import os
import numpy as np
import pandas as pd
import tensorflow as tf
import random
from typing import List, Tuple, Dict

# --- [1] ì„¤ì •ê°’ ë° ìƒìˆ˜ ---
TARGET_SIZE = (224, 224)
BATCH_SIZE = 32
GENRE_LIST: List[str] = [
    "Adventure", "Action", "RPG", "Strategy", "Simulation", "Sports", "Racing", 
    "Puzzle", "Sandbox", "Shooter", "Survival"
]

# --- [2] ë°ì´í„° ê´€ë¦¬ í´ë˜ìŠ¤ ---

class DataManager:
    """íŒŒì¼ ê²½ë¡œ ìºì‹± ë° ì¥ë¥´ë³„ ìƒ˜í”Œë§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤."""
    def __init__(self, csv_path: str, data_root_dir: str):
        self.data_root_dir = data_root_dir
        tag_df = pd.read_csv(csv_path).set_index('filename')
        
        self.filename_to_path = {}
        self.tag_vectors_map = {}
        self.genre_to_filenames = {genre: [] for genre in GENRE_LIST}

        print(f"ğŸšš ë°ì´í„° ë§¤í•‘ ë¡œë”© ì¤‘: {os.path.basename(csv_path)}")
        
        for filename, row in tag_df.iterrows():
            tag_vector = row[GENRE_LIST].values.astype(np.float32)
            
            # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ì¥ë¥´ í´ë” íƒìƒ‰ (ìµœì í™”: ì²« ë²ˆì§¸ ì¼ì¹˜ ì¥ë¥´ ì‚¬ìš©)
            path_found = None
            active_genres = [g for g in GENRE_LIST if row[g] == 1]
            
            for genre in active_genres:
                tmp_path = os.path.join(data_root_dir, genre, filename)
                if os.path.exists(tmp_path):
                    path_found = tmp_path
                    break
            
            if path_found:
                self.filename_to_path[filename] = path_found
                self.tag_vectors_map[filename] = tag_vector
                for genre in active_genres:
                    self.genre_to_filenames[genre].append(filename)

    def get_dataset_lists(self, samples_per_genre: int = None) -> Tuple[List[str], List[np.ndarray]]:
        """
        ë°ì´í„°ì…‹ ìƒì„±ì„ ìœ„í•œ ê²½ë¡œì™€ íƒœê·¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        samples_per_genreê°€ Noneì´ë©´ ëª¨ë“  ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ (ê²€ì¦ìš©).
        """
        paths, tags = [], []

        for genre in GENRE_LIST:
            fnames = self.genre_to_filenames[genre]
            if not fnames: continue

            if samples_per_genre: # í›ˆë ¨ ì‹œ: ê· í˜• ìƒ˜í”Œë§ (ë³µì› ì¶”ì¶œ í¬í•¨)
                selected = random.choices(fnames, k=samples_per_genre)
            else: # ê²€ì¦ ì‹œ: í•´ë‹¹ ì¥ë¥´ì˜ ëª¨ë“  íŒŒì¼ (ì¤‘ë³µ ì œê±° í•„ìš” ì‹œ ì¶”ê°€ ë¡œì§ ê°€ëŠ¥)
                selected = fnames
                
            for f in selected:
                paths.append(self.filename_to_path[f])
                tags.append(self.tag_vectors_map[f])
        
        return paths, tags

# --- [3] tf.data íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ---

@tf.function
def apply_augmentation(img):
    """ì•ˆì •ì ì¸ tf.image í•¨ìˆ˜ë¥¼ ì´ìš©í•œ ë°ì´í„° ì¦ê°•."""
    img = tf.image.random_flip_left_right(img)
    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)
    img = tf.image.random_brightness(img, max_delta=0.1)
    return img

def load_and_preprocess_image(file_path, tag_vector, is_training):
    """ì´ë¯¸ì§€ ë¡œë“œ, ì „ì²˜ë¦¬ ë° ì¡°ê±´ë¶€ ì¦ê°•."""
    img_raw = tf.io.read_file(file_path)
    img = tf.image.decode_image(img_raw, channels=3, expand_animations=False)
    img = tf.image.resize(img, TARGET_SIZE)
    img = tf.cast(img, tf.float32) / 255.0

    # í›ˆë ¨ ëª¨ë“œì¼ ë•Œë§Œ ì¦ê°• ì ìš©
    if is_training:
        img = apply_augmentation(img)
        
    return img, tag_vector

def create_dataset(paths_list, tags_list, batch_size: int, is_training: bool):
    """tf.data.Dataset ê°ì²´ ìƒì„± ë° ìµœì í™”."""
    dataset = tf.data.Dataset.from_tensor_slices((paths_list, tags_list))
    
    if is_training:
        dataset = dataset.shuffle(buffer_size=min(len(paths_list), 5000))
        
    dataset = dataset.map(
        lambda x, y: load_and_preprocess_image(x, y, is_training),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    
    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)

# --- [4] ì‚¬ìš© ì˜ˆì‹œ (Main) ---
if __name__ == "__main__":
    BASE_DIR = r'F:\ML\dataset'
    TRAIN_CSV = os.path.join(BASE_DIR, 'final_unique_tag_vectors.csv')
    TRAIN_IMG_DIR = os.path.join(BASE_DIR, 'Processed_224x224')

    # ë§¤ë‹ˆì € ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ìˆ˜í–‰)
    manager = DataManager(TRAIN_CSV, TRAIN_IMG_DIR)

    # ì—í­ë§ˆë‹¤ í˜¸ì¶œí•  ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì¥ë¥´ë‹¹ 1000ê°œì”© ìƒ˜í”Œë§ ì˜ˆì‹œ)
    p_list, t_list = manager.get_dataset_lists(samples_per_genre=1000)
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_ds = create_dataset(p_list, t_list, batch_size=BATCH_SIZE, is_training=True)
    print("âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")